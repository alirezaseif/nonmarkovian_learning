# The impact of memory on learning sequence-to-sequence tasks 

Here we present the code for the paper "The impact of memory on learning sequence-to-sequence tasks". Specifically, we provide the generative model needed for obtaining the data, the training code for different models, and the testing code for measuring the accuracy of the trained networks.

We consider the data generated by integrating the following stochastic differential equation $$X_{t+1} - X_{t} = - \kappa (X_t - C_t) dt + \sqrt{2D} dB_t$$. To do so, we need to first generate $C_t$ from the Gamma distribution. This is possible by using `gen_rand_lambda` function in `data_gen.py`. We then generate the particle trajectories by feeding these control sequences to `generate_forward`. 

In this work we consider three types of models for infering $C_t$ from $X_t$: auto-regressive models (AR), convolutional neural networks (CNN), and recurrent neural networks (RNN). The codes for building these models are included in `models.py`. 

By running `train.py` and specifying the `model` argument we can train the desired model. For example, `python train.py --model AR --k_value 2.5 --w_value 4 --num_epochs 40 --num_samps 50000 --run_id 0`, trains the AR(4) model with 40 epochs over 50000 trajectories generated from the Gamma distribution with $k=2.5$. Running this command will save the trained model in `models` directory. 

After the training, we can test a trained model using `test.py` by running the following command `python test.py --model AR --k_value 2.5 --w_value 4 --num_samps 10000 --run_id 0`. 
